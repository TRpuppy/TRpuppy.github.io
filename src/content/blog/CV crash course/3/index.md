---
title: 'CV crash course 03 神经网络' # (Required, max 60)
description: '他们窥见你纤柔之美，
他们艳羡你以信仰与劳作织就的宁和，
他们却无视你被奴役与长眠束缚的魂魄。
待你苏醒，真相毕露：
野兽的本性，昭然于众目。' # (Required, 10 to 160)
publishDate: '2025-12-17 00:16:00' # (Required, Date)
tags:
  - CV Crash Course
heroImage: { src: './758e4adaff6ea72fef41524e7281e178.jpg', alt: 'Hollow knight', color: '#B4C6DA' }
draft: false # (set true will only show in development)
language: 'Chinese' # (String as you like)
comment: true # (set false will disable comment, even if you've enabled it in site-config)
---

# 线性分类器

线性分类器学习训练矩阵$W$，对于数据$X$与标签$y$，最小化$||y-XW||^2$。这样的$W$的最小二乘解是$W=(X^TX)^{-1}X^Ty$。

有时候我们会引入正则化项，将Loss额外加一项$\lambda||W||^2$来惩罚过于复杂的模型。如果引入了这一项，那么$W$的最小二乘解是$W=(X^TX+\lambda I)^{-1}X^Ty$。

将多个线性层组合起来，中间加入激活函数，就可以得到多层全连接分类器(FCNN)。

此外，Loss Function我们也不再使用平方和，而是更经常采用交叉熵损失(Cross Entropy Loss)或支持向量机损失(SVM Loss)。

在较早期的研究中，一般范式是先使用启发式的特征提取(比如HoG等)，然后再使用线性分类器作图像分类任务。如果维度过高，会使用PCA的方法将主成分进行提取。

## 交叉熵损失

交叉熵损失对分类结果使用多维softmax来得到概率信息，用概率的乘积作为评估标准。在实践中会采用负对数来描述乘积。

对于单个图片$x_i$，经过分类器后得到分类结果$s$，$s$有M维，M为类数。若$x_i$实际属于第$y_i$维，则Loss为：
$$
L_i=-log(p_{y_i})\\
\text{其中，}p_k=\frac{exp(s_k)}{\sum exp(x_j)}
$$

## SVM损失

SVM损失认为正确的类别的分数至少需要比其余分数高某个𝑀𝑎𝑟𝑔𝑖𝑛值。令$t$为𝑀𝑎𝑟𝑔𝑖𝑛值，则Loss为：
$$
L_i=\sum_{j\ne y_i}max(0,s_j-s_{y_i}+t)
$$

# 神经网络

反向传播和梯度下降这一块大家肯定都知道了。与这一套对比下来，课件上说的什么网格搜索简直是笑话（

## 学习率动态衰减

下面我们主要来考虑一下学习率调整的问题。一般我们在训练开始时会采取较高的学习率，在后期时会采取较低的学习率。这涉及到学习率下降的问题。

我们在作业中使用两种学习率下降模式：Step和Cosine。

+ Step下降模式是每训练k个epochs，将学习率乘以系数$\alpha$。
+ Cosine下降模式是将epoch数均匀对应到角度区间$(0,\frac{\pi}{2})$，每个epochs的学习率为初始学习率乘以对应的余弦值。

## 反向传播——动量优化

关于反向传播部分：梯度的计算我们不需要太去关心，现在的python库早就能够做到自动进行梯度计算了。我们在意的问题是全批次进行梯度计算会导致过大的计算量。于是我们常见地会引入随机梯度下降(SGD)的方法。每次选择一个**Batch**的数据进行学习，在这个Batch上进行梯度下降。

这种方法很常见，但是有几个问题需要被优化：

+ 小Batch数据可能没有办法激活所有的神经元。如果它只激活部分神经元，就会出现部分神经元被频繁更新，部分神经元Seldom被更新的现象。下面是一个示意图，纵方向的神经元被频繁更新，造成波动，但是横方向的神经元每次只被少量更新。

  ![image-20251217164502352](image-20251217164502352.png)

+ 数据集少可能会放大噪音影响，导致无效优化甚至反向优化。
+ 可能会被局部最优困住。这一点也是梯度下降法的经典问题。

为了解决这些问题，我们引入**动量(Momentum)**的概念。如果每次计算出来的梯度是$h_t$，那么更新时候，更新值$v_t$为:
$$
v_t=\alpha_t(h_t+\rho h_{t-1}+\rho^2 h_{t-2}+...\rho^th_0)
$$
其中$\rho$是一个表示衰减比例的系数,$\alpha_t$为学习率。

这样的做法本质上是让以往的训练历史对当前的训练有影响力。让我们来看看它是怎么解决上面的问题的：

首先，对于波动的问题：如果有参数的梯度产生波动情况的话，历史上的正负梯度会相互抵消，导致最终结果没有太大的更新值。然后对于一些神经元每次只被少量更新的问题，它每次的更新值都是朝着同样的方向走的，所以历史上的梯度累计会让它更新的程度更大。引入梯度后，训练情况示意图如下所示。

![image-20251217170051951](image-20251217170051951.png)

其次，动量也能引入历史平均以减少噪声影响。它也让训练参数能有一定的"初速度"以冲出局部鞍点。

还有一种动量实现方式是**Nesterov Momentum**。这种实现和上面的实现区别在于当前梯度在哪里计算。Nesterov Momentum在每步先使用动量更新之后，在更新后的点计算梯度的方式。

## 动态学习优化器(Ada系列)

//TODO: from AdaGrad to AdamW

# 卷积神经网络

//TODO: 基本架构，卷积层，Pooling层，残差神经网络的思想，数据归一化与强化方式，Dropout处理，参数初始化方式，层归一化，ResNet与ResNext的参数量区别

